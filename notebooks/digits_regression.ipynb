{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       816\n",
      "           1       0.96      0.98      0.97       909\n",
      "           2       0.91      0.89      0.90       846\n",
      "           3       0.90      0.87      0.89       937\n",
      "           4       0.92      0.93      0.93       839\n",
      "           5       0.85      0.88      0.87       702\n",
      "           6       0.93      0.96      0.94       785\n",
      "           7       0.93      0.92      0.93       893\n",
      "           8       0.90      0.89      0.89       835\n",
      "           9       0.91      0.90      0.91       838\n",
      "\n",
      "    accuracy                           0.92      8400\n",
      "   macro avg       0.92      0.92      0.92      8400\n",
      "weighted avg       0.92      0.92      0.92      8400\n",
      "\n",
      "Confusion Matrix:\n",
      " [[787   0   1   1   3  12  10   1   1   0]\n",
      " [  0 890   4   0   1   3   1   3   6   1]\n",
      " [  4  15 756  12  12   7  11   9  20   0]\n",
      " [  1   3  27 818   0  39   2   9  24  14]\n",
      " [  4   2   4   1 782   2  10   5   5  24]\n",
      " [  6   4   8  24   9 619  17   2   9   4]\n",
      " [  8   1   7   0   4   8 752   2   3   0]\n",
      " [  0   1  10   8  14   5   1 822   5  27]\n",
      " [  3  11   6  31   7  25   6   3 739   4]\n",
      " [  5   4   5  12  15   6   0  27   8 756]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "file_path = '../data/digit-recognizer/train.csv' \n",
    "digits_images = pd.read_csv(file_path)\n",
    "\n",
    "# 1. Carregar o dataset\n",
    "# Supondo que `df` seja o DataFrame onde a primeira coluna é o label\n",
    "labels = digits_images.iloc[:, 0].values  # Coluna de rótulos (números)\n",
    "pixels = digits_images.iloc[:, 1:].values  # Colunas de pixels\n",
    "\n",
    "# 2. Pré-processamento: Normalizar os valores dos pixels\n",
    "pixels_normalized = pixels / 255.0\n",
    "\n",
    "# 3. Dividir em conjunto de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    pixels_normalized, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 4. Treinamento do modelo (Logistic Regression)\n",
    "model = LogisticRegression(max_iter=1000, solver='lbfgs')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 5. Avaliação no conjunto de teste\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       816\n",
      "           1       0.99      0.99      0.99       909\n",
      "           2       0.98      0.97      0.97       846\n",
      "           3       0.98      0.96      0.97       937\n",
      "           4       0.97      0.97      0.97       839\n",
      "           5       0.97      0.97      0.97       702\n",
      "           6       0.98      0.99      0.98       785\n",
      "           7       0.98      0.97      0.97       893\n",
      "           8       0.96      0.98      0.97       835\n",
      "           9       0.96      0.96      0.96       838\n",
      "\n",
      "    accuracy                           0.97      8400\n",
      "   macro avg       0.97      0.97      0.97      8400\n",
      "weighted avg       0.97      0.97      0.97      8400\n",
      "\n",
      "Confusion Matrix:\n",
      " [[808   0   0   0   2   1   4   0   1   0]\n",
      " [  0 901   2   0   1   1   1   1   1   1]\n",
      " [  3   4 819   2   7   0   1   3   6   1]\n",
      " [  0   0   3 903   0  10   0   6   7   8]\n",
      " [  1   0   1   0 815   1   6   2   0  13]\n",
      " [  1   1   0   9   0 682   5   0   2   2]\n",
      " [  5   1   1   0   0   1 774   0   3   0]\n",
      " [  0   2   7   0   3   1   0 866   3  11]\n",
      " [  0   2   2   6   4   3   0   1 816   1]\n",
      " [  3   1   1   6   6   2   0   7   7 805]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "svm_model = OneVsRestClassifier(SVC()).fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.24705882 0.99215686 0.4745098  0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.24705882 0.99607843 0.79215686 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.63921569 1.\n",
      " 0.56470588 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.65490196 0.98431373 0.10196078 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.03529412\n",
      " 0.83137255 0.6        0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.34901961 0.92941176 0.40784314\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.01960784 0.83921569 0.75294118 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.29019608 0.99607843\n",
      " 0.48627451 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.04705882 0.76078431 0.9372549  0.05882353 0.\n",
      " 0.         0.         0.         0.         0.23921569 0.43137255\n",
      " 0.05098039 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.10588235\n",
      " 0.99607843 0.27843137 0.         0.         0.         0.\n",
      " 0.03529412 0.51372549 0.97647059 0.99607843 0.75686275 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.43137255 0.99607843 0.12156863\n",
      " 0.         0.         0.         0.15294118 0.82352941 0.99607843\n",
      " 0.99607843 0.99607843 0.91764706 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.57647059 0.71764706 0.00392157 0.         0.00392157\n",
      " 0.50196078 0.98823529 0.99607843 0.72941176 0.72941176 0.99607843\n",
      " 0.51372549 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.25098039 0.98039216\n",
      " 0.70980392 0.         0.         0.33333333 0.99607843 0.8627451\n",
      " 0.25098039 0.05882353 0.52941176 0.99607843 0.50588235 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.32941176 0.99607843 0.65882353 0.\n",
      " 0.18431373 0.89803922 0.89019608 0.11764706 0.         0.23921569\n",
      " 0.94901961 0.96078431 0.10980392 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.32941176 0.99607843 0.30588235 0.         0.65490196 0.99215686\n",
      " 0.38431373 0.         0.05098039 0.83137255 0.99607843 0.56470588\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.30196078 0.99215686\n",
      " 0.50196078 0.29411765 0.96470588 0.57254902 0.         0.06666667\n",
      " 0.90196078 0.96862745 0.48235294 0.03137255 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.92156863 0.90588235 0.96078431\n",
      " 0.6627451  0.05882353 0.35294118 0.93333333 0.99607843 0.37647059\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.56862745 0.99607843 0.99607843 0.96470588 0.8627451\n",
      " 0.99607843 0.80392157 0.31764706 0.03529412 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.25490196\n",
      " 0.99607843 0.99607843 0.99607843 0.90196078 0.69019608 0.0745098\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.01960784 0.58039216 0.97254902\n",
      " 0.32156863 0.10588235 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "# Suponha que X contém imagens planas (n_samples x 784)\n",
    "pca = PCA(n_components=10)  # Reduzir para 50 dimensões principais\n",
    "print(X_train[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
