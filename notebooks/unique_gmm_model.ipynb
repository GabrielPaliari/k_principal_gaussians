{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "train shape: (42000, 784)\n",
      "labels shape: (42000,)\n",
      "87\n",
      "Initialization 0\n",
      "  Iteration 10\t time lapse 9.66098s\t ll change 25884.52550\n",
      "  Iteration 20\t time lapse 9.49646s\t ll change 5826.71384\n",
      "  Iteration 30\t time lapse 9.42574s\t ll change 2914.21152\n",
      "  Iteration 40\t time lapse 9.44223s\t ll change 1880.29980\n",
      "  Iteration 50\t time lapse 9.15935s\t ll change 538.91391\n",
      "  Iteration 60\t time lapse 9.42686s\t ll change 162.53658\n",
      "  Iteration 70\t time lapse 9.72263s\t ll change 64.35270\n",
      "  Iteration 80\t time lapse 9.95019s\t ll change 125.52381\n",
      "  Iteration 90\t time lapse 9.66600s\t ll change 117.77738\n",
      "  Iteration 100\t time lapse 9.78365s\t ll change 199.35508\n",
      "Initialization did not converge. time lapse 95.73409s\t lower bound -18205879.37713.\n",
      "Initialization 1\n",
      "  Iteration 10\t time lapse 9.69538s\t ll change 33330.23404\n",
      "  Iteration 20\t time lapse 9.41597s\t ll change 2010.26793\n",
      "  Iteration 30\t time lapse 9.34249s\t ll change 738.52776\n",
      "  Iteration 40\t time lapse 8.92955s\t ll change 4286.91990\n",
      "  Iteration 50\t time lapse 8.91090s\t ll change 177.52581\n",
      "  Iteration 60\t time lapse 8.94157s\t ll change 69.42713\n",
      "  Iteration 70\t time lapse 8.96452s\t ll change 20.12336\n",
      "  Iteration 80\t time lapse 9.08756s\t ll change 5.29254\n",
      "  Iteration 90\t time lapse 8.96896s\t ll change 24.41225\n",
      "  Iteration 100\t time lapse 8.97761s\t ll change 27.36453\n",
      "Initialization did not converge. time lapse 91.23450s\t lower bound -18236956.74565.\n",
      "Initialization 2\n",
      "  Iteration 10\t time lapse 9.20963s\t ll change 19760.05202\n",
      "  Iteration 20\t time lapse 8.92637s\t ll change 5025.25521\n",
      "  Iteration 30\t time lapse 9.02671s\t ll change 3306.39996\n",
      "  Iteration 40\t time lapse 9.13662s\t ll change 354.44305\n",
      "  Iteration 50\t time lapse 9.57230s\t ll change 314.27003\n",
      "  Iteration 60\t time lapse 9.06137s\t ll change 61.92363\n",
      "  Iteration 70\t time lapse 8.98800s\t ll change 44.52025\n",
      "  Iteration 80\t time lapse 9.04740s\t ll change 21.27354\n",
      "  Iteration 90\t time lapse 9.06712s\t ll change 9.97444\n",
      "  Iteration 100\t time lapse 9.07872s\t ll change 6.70169\n",
      "Initialization did not converge. time lapse 91.11423s\t lower bound -18191614.55684.\n",
      "Initialization 3\n",
      "  Iteration 10\t time lapse 9.74594s\t ll change 18909.47720\n",
      "  Iteration 20\t time lapse 9.11559s\t ll change 3352.33299\n",
      "  Iteration 30\t time lapse 8.91534s\t ll change 1712.95382\n",
      "  Iteration 40\t time lapse 9.20315s\t ll change 1973.08698\n",
      "  Iteration 50\t time lapse 9.55819s\t ll change 650.01848\n",
      "  Iteration 60\t time lapse 8.84150s\t ll change 588.41097\n",
      "  Iteration 70\t time lapse 9.06025s\t ll change 806.81441\n",
      "  Iteration 80\t time lapse 9.85562s\t ll change 1646.81763\n",
      "  Iteration 90\t time lapse 9.08184s\t ll change 380.44442\n",
      "  Iteration 100\t time lapse 8.94587s\t ll change 577.08058\n",
      "Initialization did not converge. time lapse 92.32330s\t lower bound -18199648.89184.\n",
      "Initialization 4\n",
      "  Iteration 10\t time lapse 9.57859s\t ll change 13296.58232\n",
      "  Iteration 20\t time lapse 9.18090s\t ll change 444.40512\n",
      "  Iteration 30\t time lapse 9.14205s\t ll change 195.50730\n",
      "  Iteration 40\t time lapse 9.70427s\t ll change 62.72816\n",
      "  Iteration 50\t time lapse 9.07968s\t ll change 147.31091\n",
      "  Iteration 60\t time lapse 9.33577s\t ll change 148.58618\n",
      "  Iteration 70\t time lapse 9.53242s\t ll change 260.65669\n",
      "  Iteration 80\t time lapse 9.92349s\t ll change 258.91474\n",
      "  Iteration 90\t time lapse 9.14917s\t ll change 130.09343\n",
      "  Iteration 100\t time lapse 9.01171s\t ll change 219.46132\n",
      "Initialization did not converge. time lapse 93.63905s\t lower bound -18224087.44166.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\src\\data_analysis\\venv\\lib\\site-packages\\sklearn\\mixture\\_base.py:270: ConvergenceWarning: Best performing initialization did not converge. Try different init parameters, or increase max_iter, tol, or check for degenerate data.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 88\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, point \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(validation_data):     \n\u001b[0;32m     87\u001b[0m     label \u001b[38;5;241m=\u001b[39m labels_v[idx]\n\u001b[1;32m---> 88\u001b[0m     min_distance_idx \u001b[38;5;241m=\u001b[39m \u001b[43mclassify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m     classifications_pairs\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39marray([min_distance_idx, classifications_pairs]))\n\u001b[0;32m     91\u001b[0m classifications_pairs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(classifications_pairs) \n",
      "Cell \u001b[1;32mIn[9], line 69\u001b[0m, in \u001b[0;36mclassify\u001b[1;34m(point)\u001b[0m\n\u001b[0;32m     66\u001b[0m min_distance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     67\u001b[0m best_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m n_componentes:\n\u001b[0;32m     70\u001b[0m     mean \u001b[38;5;241m=\u001b[39m means\n\u001b[0;32m     71\u001b[0m     prec \u001b[38;5;241m=\u001b[39m precisions\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Comparar o desempenho do meu modelo com outro usando apenas N \n",
    "componentes por classe e um componente geral para todas as classes.\n",
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def mahalanobis_distance(x, mean, precision):\n",
    "    \"\"\"\n",
    "    Calcula a distância de Mahalanobis de um ponto para uma distribuição gaussiana.\n",
    "    \n",
    "    Args:\n",
    "    - x: Ponto (array 1D).\n",
    "    - mean: Média da gaussiana (array 1D).\n",
    "    - cov: Matriz de covariância (array 2D).\n",
    "    \n",
    "    Retorna:\n",
    "    - Distância de Mahalanobis (float).\n",
    "    \"\"\"\n",
    "    delta = x - mean\n",
    "    dist = np.sqrt(np.dot(np.dot(delta.T, precision), delta))\n",
    "    return dist\n",
    "\n",
    "def reduce_dim_PCA(train_data, threshold):\n",
    "    pca = PCA(n_components=threshold, random_state=2)\n",
    "    transformed_data = pca.fit_transform(train_data)\n",
    "    return pca, transformed_data\n",
    "\n",
    "def load_data(file_path): \n",
    "    print(\"loading data\")\n",
    "    all_data = pd.read_csv(file_path)\n",
    "    train_data = all_data.to_numpy()[:, 1:]\n",
    "    labels = all_data.to_numpy()[:, 0]\n",
    "    print(f\"train shape: {train_data.shape}\")\n",
    "    print(f\"labels shape: {labels.shape}\")\n",
    "    \n",
    "    return train_data, labels\n",
    "\n",
    "n_componentes = 10\n",
    "threshold = 0.98\n",
    "train_data, labels = load_data('../data/digit-recognizer/train.csv')\n",
    "pca, transformed_data = reduce_dim_PCA(train_data, 0.90)\n",
    "print(pca.n_components_)\n",
    "gmm = BayesianGaussianMixture(\n",
    "    n_components=10,\n",
    "    max_iter=100,\n",
    "    covariance_type='full',\n",
    "    weight_concentration_prior_type='dirichlet_process',\n",
    "    tol=1e-4,\n",
    "    random_state=2,\n",
    "    verbose=2, \n",
    "    init_params='k-means++',\n",
    "    n_init=5,\n",
    "    warm_start=True,\n",
    ")\n",
    "\n",
    "gmm.fit(transformed_data)\n",
    "\n",
    "means = gmm.means_\n",
    "precisions = gmm.precisions_\n",
    "weights = gmm.weights_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mais frequente classe 0: 8\n",
      "0.9495459132189707\n",
      "mais frequente classe 1: 9\n",
      "0.382648401826484\n",
      "mais frequente classe 2: 4\n",
      "0.7301435406698564\n",
      "mais frequente classe 3: 2\n",
      "0.5242814667988107\n",
      "mais frequente classe 4: 3\n",
      "0.6008273009307136\n",
      "mais frequente classe 5: 7\n",
      "0.38741721854304634\n",
      "mais frequente classe 6: 1\n",
      "0.5752741774675972\n",
      "mais frequente classe 7: 5\n",
      "0.4273339749759384\n",
      "mais frequente classe 8: 7\n",
      "0.4168421052631579\n",
      "mais frequente classe 9: 3\n",
      "0.47839195979899496\n"
     ]
    }
   ],
   "source": [
    "def classify(point): \n",
    "    min_distance = float('inf')\n",
    "    best_index = -1\n",
    "\n",
    "    for idx, mean in enumerate(means):        \n",
    "        prec = precisions[idx]\n",
    "        distance = mahalanobis_distance(x=point, mean=mean, precision=prec)\n",
    "        \n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            best_index = idx\n",
    "\n",
    "    return best_index\n",
    "\n",
    "num_samples = 10000\n",
    "validation_data = pca.transform(train_data[:num_samples,:])\n",
    "labels_v = labels[:num_samples]\n",
    "\n",
    "pontos_representados = 0\n",
    "classifications_pairs = []\n",
    "\n",
    "for idx, point in enumerate(validation_data):     \n",
    "    label = labels_v[idx]\n",
    "    min_distance_idx = classify(point)\n",
    "    classifications_pairs.append(np.array([min_distance_idx, label]))\n",
    "\n",
    "classifications_pairs = np.array(classifications_pairs)\n",
    "\n",
    "for class_idx in range(10):\n",
    "    class_pairs = classifications_pairs[classifications_pairs[:,1] == class_idx] \n",
    "    coluna = class_pairs[:, 0] \n",
    "    valor, contagem = np.unique(coluna, return_counts=True)\n",
    "    mais_frequente = valor[np.argmax(contagem)]\n",
    "    print(f'mais frequente classe {class_idx}: {mais_frequente}')\n",
    "    print(np.max(contagem) / len(coluna)) \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
